{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Install Dependencies"
      ],
      "metadata": {
        "id": "EUsNSL6Tl7D2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece\n",
        "!git clone https://github.com/pytorch/fairseq\n",
        "%cd fairseq\n",
        "!pip install --editable ./\n",
        "%cd /content\n",
        "\n",
        "!pip install fairseq\n",
        "\n",
        "!pip install wandb\n",
        "# os.getcwd()\n",
        "#If Something goes wrong with the bleu score generation\n",
        "# !pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu113"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i49QsaeemHY3",
        "outputId": "c380d4ca-a795-47c0-801f-90201d1f11c0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "fatal: destination path 'fairseq' already exists and is not an empty directory.\n",
            "/content/fairseq/fairseq\n",
            "Obtaining file:///content/fairseq/fairseq\n",
            "\u001b[31mERROR: file:///content/fairseq/fairseq does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
            "\u001b[0m/content\n",
            "Requirement already satisfied: fairseq in /usr/local/lib/python3.10/dist-packages (0.12.2)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from fairseq) (1.16.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from fairseq) (3.0.6)\n",
            "Requirement already satisfied: hydra-core<1.1,>=1.0.7 in /usr/local/lib/python3.10/dist-packages (from fairseq) (1.0.7)\n",
            "Requirement already satisfied: omegaconf<2.1 in /usr/local/lib/python3.10/dist-packages (from fairseq) (2.0.6)\n",
            "Requirement already satisfied: numpy>=1.21.3 in /usr/local/lib/python3.10/dist-packages (from fairseq) (1.23.5)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fairseq) (2023.6.3)\n",
            "Requirement already satisfied: sacrebleu>=1.4.12 in /usr/local/lib/python3.10/dist-packages (from fairseq) (2.3.3)\n",
            "Collecting torch>=1.13 (from fairseq)\n",
            "  Using cached torch-2.1.1-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fairseq) (4.66.1)\n",
            "Requirement already satisfied: bitarray in /usr/local/lib/python3.10/dist-packages (from fairseq) (2.8.4)\n",
            "Requirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from fairseq) (0.12.1+cu113)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from fairseq) (1.2.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fairseq) (23.2)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.10/dist-packages (from hydra-core<1.1,>=1.0.7->fairseq) (4.8)\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq) (4.5.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq) (2.8.2)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq) (4.9.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.13->fairseq)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.13->fairseq)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.13->fairseq)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.13->fairseq)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.13->fairseq)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.13->fairseq)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.13->fairseq)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.13->fairseq)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.13->fairseq)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.18.1 (from torch>=1.13->fairseq)\n",
            "  Using cached nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.13->fairseq)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq) (2.1.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13->fairseq)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
            "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchaudio>=0.8.0 (from fairseq)\n",
            "  Downloading torchaudio-2.1.1-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->fairseq) (2.21)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fairseq) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fairseq) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fairseq) (3.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->fairseq) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->fairseq) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.12.1+cu113\n",
            "    Uninstalling torchaudio-0.12.1+cu113:\n",
            "      Successfully uninstalled torchaudio-0.12.1+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.1.1 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.1.1 which is incompatible.\n",
            "torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 2.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 torch-2.1.1 torchaudio-2.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Imports"
      ],
      "metadata": {
        "id": "2WhtkMkApOFG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdQfwv9HUdgo",
        "outputId": "68cb02ab-29cf-429d-d605-fd5479277fc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33marabic-swahilimt\u001b[0m (\u001b[33marabic-swahili\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sentencepiece as spm\n",
        "import wandb\n",
        "wandb.login(key = \"46cb1e2ffa78177f23adbe2d7d16cf09a6176348\")\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preparing File Directories"
      ],
      "metadata": {
        "id": "HkJoPAlrpUj4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/bpe_dict_path\n",
        "%mkdir /content/drive/MyDrive/logs\n",
        "!mkdir /content/train/\n",
        "!mkdir /content/test/\n",
        "!mkdir /content/val/\n",
        "!mkdir /content/train_bpe/\n",
        "!mkdir /content/test_bpe/\n",
        "!mkdir /content/val_bpe/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENVFiDkFpTqF",
        "outputId": "a9a63110-f980-445d-af2b-c4ce05c204f0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/bpe_dict_path’: File exists\n",
            "mkdir: cannot create directory ‘/content/drive/MyDrive/logs’: File exists\n",
            "mkdir: cannot create directory ‘/content/train/’: File exists\n",
            "mkdir: cannot create directory ‘/content/test/’: File exists\n",
            "mkdir: cannot create directory ‘/content/val/’: File exists\n",
            "mkdir: cannot create directory ‘/content/train_bpe/’: File exists\n",
            "mkdir: cannot create directory ‘/content/test_bpe/’: File exists\n",
            "mkdir: cannot create directory ‘/content/val_bpe/’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Preprocessing"
      ],
      "metadata": {
        "id": "yFuJCztDplAU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ruoqnb3vQt25"
      },
      "outputs": [],
      "source": [
        "#Import The data from this working Directory\n",
        "!unzip /{PATH_TO_THE_DATA_FILE}/txt_splitted_files.zip\n",
        "!unzip /{PATH_TO_THE_DATA_FILE}/DATA.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vo3CZ-iUR9K-"
      },
      "outputs": [],
      "source": [
        "#the entire files -used to train the bpe models\n",
        "All_ar_data = open(\"/content/Arabic.txt\", \"r\").readlines()\n",
        "All_sw_data = open(\"/content/Swahili.txt\",\"r\").readlines()\n",
        "# the standard training files -from it will emerge the validation set\n",
        "train_ar_data = open(\"/content/train.ar\", \"r\").readlines()\n",
        "train_sw_data = open(\"/content/train.sw\", \"r\").readlines()\n",
        "# the standard test files\n",
        "test_ar_data = open(\"/content/test.ar\", \"r\").readlines()\n",
        "test_sw_data = open(\"/content/test.sw\", \"r\").readlines()\n",
        "\n",
        "#Creating the final training set\n",
        "with open(\"/content/train/train.ar\", \"w\") as fb:\n",
        "    fb.writelines(train_ar_data[2000:])\n",
        "with open(\"/content/train/train.sw\", \"w\") as fb:\n",
        "    fb.writelines(train_sw_data[2000:])\n",
        "\n",
        "#creating a validation set from the standard training set\n",
        "with open(\"/content/val/val.ar\", \"w\") as fb:\n",
        "    fb.writelines(train_ar_data[:2000])\n",
        "with open(\"/content/val/val.sw\", \"w\") as fb:\n",
        "    fb.writelines(train_sw_data[:2000])\n",
        "\n",
        "#the Standard test set\n",
        "with open(\"/content/test/test.ar\", \"w\") as fb:\n",
        "    fb.writelines(test_ar_data)\n",
        "with open(\"/content/test/test.sw\", \"w\") as fb:\n",
        "    fb.writelines(test_sw_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IviYWnt2BmYD",
        "outputId": "b5491648-1efe-4aff-d9f4-23ab5cc744ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27531 3281 2000\n",
            "27531 3281 2000\n"
          ]
        }
      ],
      "source": [
        "#checking the splits\n",
        "train_sw_data = open(\"/content/train/train.sw\", \"r\").readlines()\n",
        "test_sw_data = open(\"/content/test/test.sw\", \"r\").readlines()\n",
        "val_sw_data = open(\"/content/val/val.sw\", \"r\").readlines()\n",
        "print(len(train_sw_data) , len(test_sw_data) ,len(val_sw_data))\n",
        "\n",
        "train_ar_data = open(\"/content/train/train.ar\", \"r\").readlines()\n",
        "test_ar_data = open(\"/content/test/test.ar\", \"r\").readlines()\n",
        "val_ar_data = open(\"/content/val/val.ar\", \"r\").readlines()\n",
        "print(len(train_ar_data) , len(test_ar_data) ,len(val_ar_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "btTtoIvXoryN"
      },
      "outputs": [],
      "source": [
        "#Training the BPE Models\n",
        "\n",
        "ar_file_path = \"/content/Arabic.txt\"\n",
        "#Arabic training file \"all arabic text\"\n",
        "sw_file_path = \"/content/Swahili.txt\"\n",
        "#swalihi_training file\n",
        "\n",
        "\n",
        "\n",
        "dict_path = \"/content/bpe_dict_path\"\n",
        "#dictionary \"create directory and name it as you like\"\n",
        "ar_train_input = \"/content/train/train.ar\"\n",
        "ar_train_bpe_output = \"/content/train_bpe/train.bpe.ar\"\n",
        "sw_train_input = \"/content/train/train.sw\"\n",
        "sw_train_bpe_output = \"/content/train_bpe/train.bpe.sw\"\n",
        "\n",
        "ar_val_input = \"/content/val/val.ar\"\n",
        "ar_val_bpe_output = \"/content/val_bpe/val.bpe.ar\"\n",
        "sw_val_input = \"/content/val/val.sw\"\n",
        "sw_val_bpe_output = \"/content/val_bpe/val.bpe.sw\"\n",
        "\n",
        "ar_test_input = \"/content/test/test.ar\"\n",
        "ar_test_bpe_output = \"/content/test_bpe/test.bpe.ar\"\n",
        "sw_test_input = \"/content/test/test.sw\"\n",
        "sw_test_bpe_output = \"/content/test_bpe/test.bpe.sw\"\n",
        "\n",
        "vocab_size = 12000\n",
        "\n",
        "\n",
        "sw_source_file = \"/content/Swahili.txt\"\n",
        "ar_source_file = \"/content/Arabic.txt\"\n",
        "\n",
        "# joint_vocab_file = \"/content/joint_train.txt\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#using entire text to found the dictonary for the BPE\n",
        "def train_ar(vocab_size):\n",
        "  model_prefix = dict_path+\"/ar_\" + \"_vocab_\" + str(vocab_size)\n",
        "  spm.SentencePieceTrainer.train(input=ar_source_file\n",
        "      , model_prefix=model_prefix\n",
        "      , vocab_size=vocab_size\n",
        "      , character_coverage = 0.9995\n",
        "      , num_threads=60\n",
        "      , model_type = \"bpe\"\n",
        "      , train_extremely_large_corpus=True\n",
        "  )\n",
        "train_ar(vocab_size)\n",
        "\n",
        "def train_sw(vocab_size):\n",
        "  model_prefix = dict_path + \"/swahil_\" + \"_vocab_\" + str(vocab_size)\n",
        "  spm.SentencePieceTrainer.train(input=sw_source_file\n",
        "      , model_prefix=model_prefix\n",
        "      , vocab_size=vocab_size\n",
        "      , character_coverage = 0.9995\n",
        "      , num_threads=60\n",
        "      ,model_type = \"bpe\"\n",
        "      , train_extremely_large_corpus=True\n",
        "  )\n",
        "train_sw(vocab_size)\n",
        "\n",
        "ar_tokenizer = spm.SentencePieceProcessor(model_file=\"/content/bpe_dict_path/ar__vocab_12000.model\")\n",
        "sw_tokenizer = spm.SentencePieceProcessor(model_file=\"/content/bpe_dict_path/swahil__vocab_12000.model\")\n",
        "\n",
        "\n",
        "#from the above the BPE models are trained\n",
        "####################################\n",
        "\n",
        "\n",
        "#lines uses the Arabic BPE model to tokenize the Arabic training data\n",
        "with open(ar_train_input, \"r\", encoding=\"utf-8\") as rf, open(ar_train_bpe_output, \"w\", encoding=\"utf-8\") as wf:\n",
        "    output_lines = []\n",
        "    for line in rf.readlines():\n",
        "        wf.write(' '.join(ar_tokenizer.encode(line, out_type=str)))\n",
        "        wf.write(\"\\n\")\n",
        "\n",
        "\n",
        "with open(sw_train_input, \"r\", encoding=\"utf-8\") as rf, open(sw_train_bpe_output, \"w\", encoding=\"utf-8\") as wf:\n",
        "    output_lines = []\n",
        "    for line in rf.readlines():\n",
        "        wf.write(' '.join(sw_tokenizer.encode(line, out_type=str)))\n",
        "        wf.write(\"\\n\")\n",
        "\n",
        "\n",
        "with open(ar_test_input, \"r\", encoding=\"utf-8\") as rf, open(ar_test_bpe_output, \"w\", encoding=\"utf-8\") as wf:\n",
        "    output_lines = []\n",
        "    for line in rf.readlines():\n",
        "        wf.write(' '.join(ar_tokenizer.encode(line, out_type=str)))\n",
        "        wf.write(\"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "with open(sw_test_input, \"r\", encoding=\"utf-8\") as rf, open(sw_test_bpe_output, \"w\", encoding=\"utf-8\") as wf:\n",
        "    output_lines = []\n",
        "    for line in rf.readlines():\n",
        "        wf.write(' '.join(sw_tokenizer.encode(line, out_type=str)))\n",
        "        wf.write(\"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "with open(ar_val_input, \"r\", encoding=\"utf-8\") as rf, open(ar_val_bpe_output, \"w\", encoding=\"utf-8\") as wf:\n",
        "    output_lines = []\n",
        "    for line in rf.readlines():\n",
        "        wf.write(' '.join(ar_tokenizer.encode(line, out_type=str)))\n",
        "        wf.write(\"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "with open(sw_val_input, \"r\", encoding=\"utf-8\") as rf, open(sw_val_bpe_output, \"w\", encoding=\"utf-8\") as wf:\n",
        "    output_lines = []\n",
        "    for line in rf.readlines():\n",
        "        wf.write(' '.join(sw_tokenizer.encode(line, out_type=str)))\n",
        "        wf.write(\"\\n\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6wvj-XCbqBHH"
      },
      "outputs": [],
      "source": [
        "!cut -f1 \"/content/bpe_dict_path/ar__vocab_12000.vocab\" | tail -n +4 | sed \"s/$/ 100/g\" > \"/content/bpe_dict_path/fairseq.ar.vocab\"\n",
        "!cut -f1 \"/content/bpe_dict_path/swahil__vocab_12000.vocab\" | tail -n +4 | sed \"s/$/ 100/g\" > \"/content/bpe_dict_path/fairseq.sw.vocab\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVZ5WBcqo-Ix"
      },
      "source": [
        "##FAIRSEQ Preprocess \"Prepare the data to go into the Transformer\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mPeXgGLo-8M",
        "outputId": "c6fd2503-5cdb-4bda-a1a9-ce562444b96d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-07 19:15:47.710713: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-07 19:15:47.710785: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-07 19:15:47.710828: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-07 19:15:47.724386: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-12-07 19:15:50.362199: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX\n",
            "INFO:fairseq_cli.preprocess:Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='translation', source_lang='ar', target_lang='sw', trainpref='/content/train_bpe/train.bpe', validpref='/content/val_bpe/val.bpe', testpref='/content/test_bpe/test.bpe', align_suffix='align', destdir='/content/ar_sw.tokenized.ar-sw', thresholdtgt=0, thresholdsrc=0, tgtdict='/content/bpe_dict_path/fairseq.sw.vocab', srcdict='/content/bpe_dict_path/fairseq.ar.vocab', nwordstgt=-1, nwordssrc=-1, alignfile=None, dataset_impl='mmap', joined_dictionary=False, only_source=False, padding_factor=8, workers=1, dict_only=False)\n",
            "INFO:fairseq_cli.preprocess:[ar] Dictionary: 12001 types\n",
            "INFO:fairseq_cli.preprocess:[ar] /content/train_bpe/train.bpe.ar: 27531 sents, 670052 tokens, 0.0848% replaced (by <unk>)\n",
            "INFO:fairseq_cli.preprocess:[ar] Dictionary: 12001 types\n",
            "INFO:fairseq_cli.preprocess:[ar] /content/val_bpe/val.bpe.ar: 2000 sents, 49021 tokens, 0.0959% replaced (by <unk>)\n",
            "INFO:fairseq_cli.preprocess:[ar] Dictionary: 12001 types\n",
            "INFO:fairseq_cli.preprocess:[ar] /content/test_bpe/test.bpe.ar: 3281 sents, 78920 tokens, 0.0672% replaced (by <unk>)\n",
            "INFO:fairseq_cli.preprocess:[sw] Dictionary: 12001 types\n",
            "INFO:fairseq_cli.preprocess:[sw] /content/train_bpe/train.bpe.sw: 27531 sents, 715812 tokens, 0.138% replaced (by <unk>)\n",
            "INFO:fairseq_cli.preprocess:[sw] Dictionary: 12001 types\n",
            "INFO:fairseq_cli.preprocess:[sw] /content/val_bpe/val.bpe.sw: 2000 sents, 52161 tokens, 0.144% replaced (by <unk>)\n",
            "INFO:fairseq_cli.preprocess:[sw] Dictionary: 12001 types\n",
            "INFO:fairseq_cli.preprocess:[sw] /content/test_bpe/test.bpe.sw: 3281 sents, 84840 tokens, 0.141% replaced (by <unk>)\n",
            "INFO:fairseq_cli.preprocess:Wrote preprocessed data to /content/ar_sw.tokenized.ar-sw\n"
          ]
        }
      ],
      "source": [
        "SOURCE_LANGUAGE=\"ar\"\n",
        "TARGET_LANGUAGE=\"sw\"\n",
        "TRAIN_PREF=\"/content/train_bpe/train.bpe\"\n",
        "VALID_PREF=\"/content/val_bpe/val.bpe\"\n",
        "TEST_PREF=\"/content/test_bpe/test.bpe\"\n",
        "DEST_DIR=\"/content/ar_sw.tokenized.ar-sw\"\n",
        "SRC_THRES=0\n",
        "TGT_THRES=0\n",
        "ar_DICT_PATH=\"/content/bpe_dict_path/fairseq.ar.vocab\"\n",
        "swahili_DICT_PATH=\"/content/bpe_dict_path/fairseq.sw.vocab\"\n",
        "\n",
        "!fairseq-preprocess    --source-lang $SOURCE_LANGUAGE --target-lang $TARGET_LANGUAGE  \\\n",
        "   --srcdict \"/content/bpe_dict_path/fairseq.ar.vocab\"    --tgtdict \"/content/bpe_dict_path/fairseq.sw.vocab\"  --align-suffix align     --trainpref  $TRAIN_PREF        --validpref $VALID_PREF     --testpref $TEST_PREF   --destdir  $DEST_DIR     --thresholdsrc $SRC_THRES     --thresholdtgt $TGT_THRES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ij0c-73pCjQ"
      },
      "source": [
        "##FAIRSEQ Training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MtTqnjZpEb6"
      },
      "outputs": [],
      "source": [
        "DROPOUT=0.1\n",
        "ATTENTION_DROPOUT=0\n",
        "ACTIVATION_DROPOUT=0.1\n",
        "EMBEDDING_SIZE=256\n",
        "ENC_FFNN=1024\n",
        "ENCODER_LAYERS=5\n",
        "ENCODER_ATTENTION_HEADS=8\n",
        "DECODER_LAYERS=5\n",
        "DECODER_ATTENTION_HEADS=8\n",
        "DEC_FFNN=1024\n",
        "EPOCH=400\n",
        "BATCH_SIZE=4096\n",
        "ENCODER_LAYER_DROPOUT=0.1\n",
        "DECODER_LAYER_DROPOUT=0.1\n",
        "LABEL_SMOOTHING=0.1\n",
        "SAVE_DIR=\"/content/drive/MyDrive/ironside_nmt/checkpoints/\"\n",
        "LABEL_CROSS_ENTROPY=\"label_smoothed_cross_entropy\"\n",
        "WARMUP_UPDATES=4000\n",
        "lEARNING_POLICY=\"inverse_sqrt\"\n",
        "WAND_PROJECT_NAME=\"LARGE_SCALE_ARSWAHILI_Translation\"\n",
        "\n",
        "!fairseq-train \"/content/ar_sw.tokenized.ar-sw\" \\\n",
        "    --arch transformer \\\n",
        "    --dropout $DROPOUT \\\n",
        "    --attention-dropout 0     --encoder-embed-dim $EMBEDDING_SIZE \\\n",
        "    --encoder-ffn-embed-dim $ENC_FFNN  \\\n",
        "    --encoder-layers $ENCODER_LAYERS  \\\n",
        "    --encoder-attention-heads $ENCODER_ATTENTION_HEADS \\\n",
        "    --encoder-learned-pos  \\\n",
        "    --decoder-embed-dim $EMBEDDING_SIZE \\\n",
        "    --decoder-ffn-embed-dim $DEC_FFNN  \\\n",
        "    --decoder-layers $DECODER_LAYERS \\\n",
        "    --decoder-attention-heads $DECODER_ATTENTION_HEADS \\\n",
        "    --decoder-learned-pos   \\\n",
        "    --max-epoch $EPOCH  \\\n",
        "    --optimizer adam \\\n",
        "    --lr 5e-4 \\\n",
        "    --max-tokens $BATCH_SIZE \\\n",
        "    --seed 1     --encoder-layerdrop $ENCODER_LAYER_DROPOUT     --decoder-layerdrop $DECODER_LAYER_DROPOUT \\\n",
        "    --criterion $LABEL_CROSS_ENTROPY     --warmup-updates $WARMUP_UPDATES \\\n",
        "    --source-lang ar    --label-smoothing $LABEL_SMOOTHING \\\n",
        "    --lr-scheduler $lEARNING_POLICY   --save-dir $SAVE_DIR \\\n",
        "    --find-unused-parameters  \\\n",
        "    --target-lang sw \\\n",
        "    --activation-dropout $ACTIVATION_DROPOUT  \\\n",
        "    --ddp-backend=no_c10d \\\n",
        "    --no-epoch-checkpoints --wandb-project $WAND_PROJECT_NAME \\\n",
        "    --log-format=json --log-interval=10 2>&1    |  tee  \"/content/drive/MyDrive/logs/training_log.log\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4b4MF8FpI7b"
      },
      "source": [
        "##FAIRSEQ Generating BLEU score (Testing)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4O0kSetpNiG",
        "outputId": "a06af825-a323-4547-9dee-99c4d74efe10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-07 19:23:01.979698: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-07 19:23:01.979767: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-07 19:23:01.979812: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-07 19:23:01.994258: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-12-07 19:23:03.566048: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX\n",
            "DEBUG:hydra.core.utils:Setting JobRuntime:name=UNKNOWN_NAME\n",
            "DEBUG:hydra.core.utils:Setting JobRuntime:name=utils\n",
            "INFO:fairseq_cli.generate:{'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '/content/drive/MyDrive/ironside_nmt/checkpoints/checkpoint_last.pt', 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 128, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 128, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'adp_num': -1, 'adp_dim': 64, 'adp_act_fn': 'relu', 'adp_trf_idx': 'all'}, 'task': {'_name': 'translation', 'data': '/content/ar_sw.tokenized.ar-sw', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
            "INFO:fairseq.tasks.translation:[ar] dictionary: 12001 types\n",
            "INFO:fairseq.tasks.translation:[sw] dictionary: 12001 types\n",
            "INFO:fairseq_cli.generate:loading model(s) from /content/drive/MyDrive/ironside_nmt/checkpoints/checkpoint_last.pt\n",
            "INFO:fairseq.data.data_utils:loaded 3,281 examples from: /content/ar_sw.tokenized.ar-sw/test.ar-sw.ar\n",
            "INFO:fairseq.data.data_utils:loaded 3,281 examples from: /content/ar_sw.tokenized.ar-sw/test.ar-sw.sw\n",
            "INFO:fairseq.tasks.translation:/content/ar_sw.tokenized.ar-sw test ar-sw 3281 examples\n",
            "INFO:fairseq.tasks.fairseq_task:can_reuse_epoch_itr = True\n",
            "INFO:fairseq.tasks.fairseq_task:reuse_dataloader = True\n",
            "INFO:fairseq.tasks.fairseq_task:rebuild_batches = False\n",
            "INFO:fairseq.tasks.fairseq_task:creating new batches for epoch 1\n",
            "INFO:fairseq_cli.generate:NOTE: hypothesis and token scores are output in base 2\n",
            "INFO:fairseq_cli.generate:Translated 3,280 sentences (80,094 tokens) in 19.1s (171.68 sentences/s, 4192.13 tokens/s)\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE=128\n",
        "BEAM=5\n",
        "SEED=1\n",
        "SCORING=\"bleu\"\n",
        "CHECKPOINT_PATH=\"/content/drive/MyDrive/ironside_nmt/checkpoints/checkpoint_last.pt\"\n",
        "    # --remove-bpe 'sentencepiece' \\\n",
        "\n",
        "!fairseq-generate \"/content/ar_sw.tokenized.ar-sw\"\\\n",
        "    --batch-size $BATCH_SIZE \\\n",
        "    --beam $BEAM \\\n",
        "    --path $CHECKPOINT_PATH \\\n",
        "    --remove-bpe 'sentencepiece' \\\n",
        "    --seed $SEED \\\n",
        "    --scoring bleu > \"/content/results.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqp-fv_EfF_Q",
        "outputId": "0daa3756-bbf6-45a4-a413-afc41baa34b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU4 = 11.71,\n"
          ]
        }
      ],
      "source": [
        "with open( \"/content/results.txt\" ) as f:\n",
        "  text = f.read()\n",
        "  text = text.split()\n",
        "  print(\" \".join(text[-8:-5]))\n",
        "  # BLEU4 acheived 11.25, after 150 epochs\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}